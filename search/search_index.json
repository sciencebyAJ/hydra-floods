{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the HYDRAFloods Documentation The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The bases behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms in a simple API. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine. Quick Start To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers, which experiences frequent flooding. # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about the package throughout the documentation such as installation , the algorithms available , or setting up the package to run operationally using the CLI . Get in touch Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\" Contribute Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started. License hydrafloods is available under the open source GNU General Public License v3.0 .","title":"Overview"},{"location":"#welcome-to-the-hydrafloods-documentation","text":"The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The bases behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms in a simple API. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine.","title":"Welcome to the HYDRAFloods Documentation"},{"location":"#quick-start","text":"To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers, which experiences frequent flooding. # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about the package throughout the documentation such as installation , the algorithms available , or setting up the package to run operationally using the CLI .","title":"Quick Start"},{"location":"#get-in-touch","text":"Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\"","title":"Get in touch"},{"location":"#contribute","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started.","title":"Contribute"},{"location":"#license","text":"hydrafloods is available under the open source GNU General Public License v3.0 .","title":"License"},{"location":"algorithms/","text":"","title":"Algorithms"},{"location":"api/","text":"","title":"API Reference"},{"location":"applications/","text":"","title":"Applications"},{"location":"cli/","text":"","title":"Command Line Interface"},{"location":"datasets/","text":"Datasets Dataset structure Working with Datasets Writing your own dataset class","title":"Datasets"},{"location":"datasets/#datasets","text":"","title":"Datasets"},{"location":"datasets/#dataset-structure","text":"","title":"Dataset structure"},{"location":"datasets/#working-with-datasets","text":"","title":"Working with Datasets"},{"location":"datasets/#writing-your-own-dataset-class","text":"","title":"Writing your own dataset class"},{"location":"getting-started/","text":"","title":"Getting Started"},{"location":"installation/","text":"Installation hydrafloods itself is a pure Python package, but its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one through a Docker Image and another via a manual installation. Using the Docker Image The easiest way to get up and started using the hydrafloods packages is via a Docker Image. The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations, such as GDAL. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run -it \\ -v ~/<PROJECT-DIR>/:/mnt/<PROJECT-DIR> \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROEJCT-DIR> ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECTD-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation . Manual installation Another convient way to install the package and its dependencies is using anaconda . It is recommend using the community maintained conda-forge channel to handle dependencies. Furthermore, it is good practice to use a virtual environment within conda. To create a new environment, install dependencies, and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 \\ numpy \\ scipy \\ pandas \\ requests \\ yaml \\ xmltodict \\ gdal \\ shapely \\ pyproj \\ netCDF4 \\ xarray \\ pyresample \\ geopandas \\ earthengine-api \\ fire -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install simplecmr hydrafloods You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies has been installed successfully, you will need to authenticate the cloud APIs Cloud authentication After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation! Testing installation \ud83d\udea7 Coming soon! \ud83d\udea7","title":"Installation"},{"location":"installation/#installation","text":"hydrafloods itself is a pure Python package, but its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one through a Docker Image and another via a manual installation.","title":"Installation"},{"location":"installation/#using-the-docker-image","text":"The easiest way to get up and started using the hydrafloods packages is via a Docker Image. The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations, such as GDAL. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run -it \\ -v ~/<PROJECT-DIR>/:/mnt/<PROJECT-DIR> \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROEJCT-DIR> ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECTD-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation .","title":"Using the Docker Image"},{"location":"installation/#manual-installation","text":"Another convient way to install the package and its dependencies is using anaconda . It is recommend using the community maintained conda-forge channel to handle dependencies. Furthermore, it is good practice to use a virtual environment within conda. To create a new environment, install dependencies, and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 \\ numpy \\ scipy \\ pandas \\ requests \\ yaml \\ xmltodict \\ gdal \\ shapely \\ pyproj \\ netCDF4 \\ xarray \\ pyresample \\ geopandas \\ earthengine-api \\ fire -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install simplecmr hydrafloods You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies has been installed successfully, you will need to authenticate the cloud APIs","title":"Manual installation"},{"location":"installation/#cloud-authentication","text":"After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation!","title":"Cloud authentication"},{"location":"installation/#testing-installation","text":"\ud83d\udea7 Coming soon! \ud83d\udea7","title":"Testing installation"}]}